{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Y48HukVGD54z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663698080162,"user_tz":-120,"elapsed":400,"user":{"displayName":"Osman Alb","userId":"12971803444625997364"}},"outputId":"78f504dd-c237-430d-a1df-194e2963a3e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Sep 20 18:21:19 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   37C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"H8NB6bVLD548","executionInfo":{"status":"ok","timestamp":1663698080550,"user_tz":-120,"elapsed":3,"user":{"displayName":"Osman Alb","userId":"12971803444625997364"}}},"outputs":[],"source":["import os\n","os.environ[\"WANDB_DISABLED\"] = \"true\""]},{"cell_type":"code","execution_count":3,"metadata":{"id":"KNgWM7TID55A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663698099452,"user_tz":-120,"elapsed":18905,"user":{"displayName":"Osman Alb","userId":"12971803444625997364"}},"outputId":"81c0e482-53c8-49b4-a052-e74f202293d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# load folder\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"WX5X9d_9D55F","executionInfo":{"status":"ok","timestamp":1663698099453,"user_tz":-120,"elapsed":4,"user":{"displayName":"Osman Alb","userId":"12971803444625997364"}}},"outputs":[],"source":["# please change the path of your dataset here below\n","ROOT_PATH = \"/content/drive/MyDrive/colab notebook/data_exp/german_med_termss/\"\n","# ROOT_PATH= \"updated_german_med_terms/\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ol1_d3YGD55I","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ff0b305b-ec51-4e50-db03-d270527063fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.22.1-py3-none-any.whl (4.9 MB)\n","\u001b[K     |████████████████████████████████| 4.9 MB 10.2 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Collecting huggingface-hub<1.0,>=0.9.0\n","  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n","\u001b[K     |████████████████████████████████| 120 kB 55.7 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 43.0 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.22.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch-lightning\n","  Downloading pytorch_lightning-1.7.6-py3-none-any.whl (707 kB)\n","\u001b[K     |████████████████████████████████| 707 kB 8.4 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.21.6)\n","Collecting torchmetrics>=0.7.0\n","  Downloading torchmetrics-0.9.3-py3-none-any.whl (419 kB)\n","\u001b[K     |████████████████████████████████| 419 kB 43.2 MB/s \n","\u001b[?25hRequirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2022.8.2)\n","Collecting pyDeprecate>=0.3.1\n","  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.64.1)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.1.1)\n","Collecting tensorboard>=2.9.1\n","  Downloading tensorboard-2.10.0-py3-none-any.whl (5.9 MB)\n","\u001b[K     |████████████████████████████████| 5.9 MB 30.0 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (21.3)\n","Requirement already satisfied: torch>=1.9.* in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.12.1+cu113)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.23.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.8.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (4.0.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.2.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.1.1)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (0.13.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.8.1)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.3.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (6.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (22.1.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning) (3.0.9)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (57.4.0)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (3.17.3)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.2.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.35.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.48.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (0.6.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (0.4.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.8.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (3.4.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch-lightning) (0.37.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (0.2.8)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (1.15.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (4.9)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.9.1->pytorch-lightning) (4.12.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.9.1->pytorch-lightning) (3.8.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2022.6.15)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning) (3.2.0)\n"]}],"source":["# # install all needed libraries\n","# !pip install transformers\n","# !pip install pytorch-lightning\n","# !pip install transformers datasets --quiet\n","# !pip install -U imbalanced-learn\n","# !pip install scikit-multilearn\n","\n","# !pip install spacy\n","# !pip install spacy-transformers\n","# !python3 -m spacy download de_dep_news_trf\n","# !python3 -m spacy download de_core_news_lg\n","\n","# # !python -m spacy download de_dep_news_trf\n","\n","!pip install transformers\n","!pip install pytorch-lightning\n","!pip install transformers datasets --quiet\n","!pip install -U imbalanced-learn\n","!pip install scikit-multilearn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_YXygSwCD55M"},"outputs":[],"source":["import torch\n","from transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\n","from transformers import BertTokenizerFast, BertForSequenceClassification, BertTokenizer, BertForMultipleChoice\n","from transformers import Trainer, TrainingArguments\n","import numpy as np\n","import random\n","from sklearn.model_selection import train_test_split\n","import os\n","import pandas as pd\n","import ast\n","import seaborn as sns\n","from sklearn.preprocessing import LabelEncoder\n","from imblearn.under_sampling import RandomUnderSampler\n","import datasets\n","from datasets import Dataset\n","\n","import torch\n","from transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\n","from transformers import BertTokenizerFast, BertForSequenceClassification, BertTokenizer\n","from transformers import Trainer, TrainingArguments\n","import numpy as np\n","import random\n","from sklearn.model_selection import train_test_split\n","import os\n","import pandas as pd\n","import ast\n","import seaborn as sns\n","from sklearn.preprocessing import LabelEncoder\n","from imblearn.under_sampling import RandomUnderSampler\n","import datasets\n","from datasets import Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OuQW3Y_VD55P"},"outputs":[],"source":["files = os.listdir(ROOT_PATH)\n","filepaths = [ROOT_PATH + f for f in os.listdir(ROOT_PATH) if f.endswith('.csv')]\n","df = pd.concat(map(pd.read_csv, filepaths))\n","df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZOipfAZsD55T"},"outputs":[],"source":["def tx(x):\n","  res = []\n","  for v in ast.literal_eval(x):\n","    res.append(str(v).strip().lower())\n","  return res\n","\n","\n","df['labels_array']= df['expertise'].apply(lambda x: tx(x))\n","df = df[pd.notna(df['labels_array'])]\n","df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8qAwlMBzcC2d"},"outputs":[],"source":["def get_categories_with_index(labels_classfified: dict):\n","    categories = []\n","    main = labels_classfified['Unnamed: 1']\n","    for k,v in main.items():\n","        if type(v) == str:\n","            categories.append(v)\n","    \n","    categories_with_index = []\n","    for i in range(len(categories) -1 ):\n","        start = list(main.values()).index(str(categories[i]))\n","        end = list(main.values()).index(str(categories[i + 1])) - 1\n","\n","        main_category = str(categories[i]).lower()\n","        categories_with_index.append({\"category\": categories[i], \"start\": start, \"end\": end, \"values\": [main_category]})\n","    \n","    # for the last category\n","    last_category = categories[-1].lower()\n","    categories_with_index.append({\"category\": last_category, \"start\": -1, \"end\": -1, \"values\": [last_category]})\n","    \n","    columns = list(labels_classfified.keys())[2:]\n","    for v in columns:\n","        for ci in categories_with_index:\n","            ci['category'] = str(ci['category']).lower()\n","            ci['values'] += found(labels_classfified[v], ci)\n","        \n","    return categories_with_index\n","\n","def found(dict_under, ci):\n","    values = []\n","    for k,v in dict_under.items():\n","        if k > ci['start'] and k < ci['end'] and type(v) == str:\n","            values += [str(v).lower()]\n","    \n","    return list(set(values))\n","\n","categories_with_index = get_categories_with_index(pd.read_excel('../content/drive/MyDrive/colab notebook/Praxisprojekt_MMC.xlsx').to_dict())\n","# categories_with_index = get_categories_with_index(pd.read_excel('Praxisprojekt_MMC.xlsx').to_dict())\n","target_names = [c['category'] for c in categories_with_index]\n","print(target_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TAUNp_rHcC2f"},"outputs":[],"source":["def change_label_to_main_category(x):\n","    result = []\n","    for value_from_x in x:\n","        for ci in categories_with_index:\n","            if value_from_x in ci['values']:\n","                result.append(ci['category'])\n","\n","    return list(set(result))\n","\n","df['labels_array']= df['labels_array'].apply(lambda x: change_label_to_main_category(x))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OH7nkKXXcC2g"},"outputs":[],"source":["print(df['labels_array'].value_counts())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"29LAlRnXcC2h"},"outputs":[],"source":["\n","def get_number_of_sample_per_label(df, number_of_sample_per_label):\n","    result = []\n","\n","    for label, count in df['labels_array'].value_counts().items():\n","        if count <= number_of_sample_per_label:\n","            result += [label]\n","\n","    print(\"count -> \", len(result))\n","    return result\n","\n","found_labels = get_number_of_sample_per_label(df, 1)\n","print(found_labels)\n","\n","if len(found_labels) > 0:\n","    ri = []\n","    for index, row in df.iterrows():\n","        for l in found_labels:\n","            if l == row['labels_array']:\n","                ri.append(index)\n","\n","    print(\"ri\", ri)\n","    df.drop(index=ri, inplace = True)\n","    df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZcCBe7-icC2i"},"outputs":[],"source":["print(df['labels_array'].value_counts())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M8CyuVR3cC2j"},"outputs":[],"source":["df_train, df_val = train_test_split(df, test_size=0.2, random_state=42, stratify=df['labels_array'])\n","print(df_train.shape, df_val.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GF33Tg1vcC2j"},"outputs":[],"source":["def explode_doc(df):\n","    df['doc'] = df[['all_page', 'wiki_content']].apply(lambda x: [str(x['all_page']) ]+ [str(x['wiki_content']) ], axis=1)\n","    df = df.explode(\"doc\")\n","\n","    df = df[pd.notna(df['doc'])]\n","    df['doc'] = df['doc'].replace('nan', np.nan)\n","    df.dropna(subset=['doc'], inplace=True)  \n","\n","    return df\n","\n","def explode_labels_array(df):\n","\n","    df = df.explode(\"labels_array\")\n","    df.rename(columns = {'labels_array': 'label'}, inplace = True)\n","\n","    df['label'].replace('', np.nan, inplace=True)\n","    df.dropna(subset=['label'], inplace=True) \n","\n","    sns.set(rc={'figure.figsize':(11.7,8.27)})\n","    sns.countplot(data=df, y=\"label\", orient=\"v\")\n","\n","    return df\n","\n","def get_label_encoder(df):\n","    label_encoder = LabelEncoder()\n","    df['label'] = label_encoder.fit_transform(df['label'])\n","    # df['label'] = df['label'].apply(str)\n","\n","    le_name_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n","    print(le_name_mapping)\n","    \n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2klMqZ78D55s"},"outputs":[],"source":["# print(\"---------------------------LABELS ARRAYS--------------------------------\")\n","# print(df_train['labels_array'].value_counts())\n","# print(\"-----------------------------------------------------------------\")\n","# print(df_val['labels_array'].value_counts())\n","\n","\n","df_train = get_label_encoder(explode_labels_array(explode_doc(df_train)))\n","df_val = get_label_encoder(explode_labels_array(explode_doc(df_val)))\n","\n","print(df_train.shape)\n","print(df_val.shape)\n","\n","# print(\"---------------------------LABELS--------------------------------\")\n","# print(df_train['label'].value_counts())\n","# print(\"-----------------------------------------------------------------\")\n","# print(df_val['label'].value_counts())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MMV3MQ7ScC2k"},"outputs":[],"source":["###################################################################\n","# df_train = df_train.head(10)\n","# df_val = df_val.head(2)\n","####################################################################"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ODL3YDlecC2l"},"outputs":[],"source":["models = [\n","    \"emilyalsentzer/Bio_ClinicalBERT\", # \n","    \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\", # \n","    \"bert-base-uncased\", # epoch = 2 --> F1 = 0.5346\n","    \"fspanda/Medical-Bio-BERT2\", #  \"----------------------------\"\n","    \"bert-base-multilingual-cased\", #\n","    \"bert-base-german-cased\", #\n","    \"smanjil/German-MedBERT\", #\n","    \"deutsche-telekom/bert-multi-english-german-squad2\", #\n","]\n","\n","\n","PRE_TRAINED_MODEL_NAME = models[5] # models[6] need 25 epochs for training\n","print(PRE_TRAINED_MODEL_NAME)\n","\n","MAX_LEN = 512\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8zVr_4pEcC2m"},"outputs":[],"source":["tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cbS7-bWNcC2n"},"outputs":[],"source":["train_encodings = tokenizer(df_train['doc'].tolist(), truncation=True, padding=True, max_length=MAX_LEN)\n","valid_encodings = tokenizer(df_val['doc'].tolist(), truncation=True, padding=True, max_length=MAX_LEN)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IYUr3nshcC2n"},"outputs":[],"source":["class ExpDataset(torch.utils.data.Dataset):\n","    def __init__(self, docs, labels):\n","        self.docs = docs\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {k: torch.tensor(v[idx]) for k, v in self.docs.items()}\n","        item[\"labels\"] = torch.tensor([self.labels.values[idx]])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wBlWg6bScC2n"},"outputs":[],"source":["train_dataset = ExpDataset(train_encodings, df_train['label'])\n","valid_dataset = ExpDataset(valid_encodings, df_val['label'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iTmjVhE0cC2o"},"outputs":[],"source":["NUM_LABELS = len(list(set(df_train['label'].tolist()))) # len(np.unique(df_train['label'])) neu hunzugefugt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x0xlB_H-cC2o"},"outputs":[],"source":["model = BertForSequenceClassification.from_pretrained(PRE_TRAINED_MODEL_NAME, num_labels=NUM_LABELS).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PFlOnUN_cC2p"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report, ConfusionMatrixDisplay\n","from sklearn.metrics import plot_confusion_matrix\n","\n","def compute_metrics(pred):\n","  labels = pred.label_ids\n","  preds = pred.predictions.argmax(-1)\n","\n","  print(\"classification_report --> HERE BELOW\")\n","  print(classification_report(labels, preds))\n","\n","  f1_score_micro = f1_score(labels, preds, average=\"micro\")\n","  accuracy = accuracy_score(labels, preds)\n","  recall = recall_score(labels, preds, average=\"micro\")\n","  precision = precision_score(labels, preds, average=\"micro\")\n","\n","  return {'F1_score' : f1_score_micro ,'Accuracy' : accuracy, 'Recall' :recall, 'Precision' : precision}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GNBvYHODcC2q"},"outputs":[],"source":["training_args = TrainingArguments(\n","    output_dir='./results',          # output directory\n","    num_train_epochs=10,# total number of training epochs\n","    learning_rate=2e-5,\n","    #fp16 = True,\n","    per_device_train_batch_size=8,  # batch size per device during training\n","    per_device_eval_batch_size=8,   # batch size for evaluation\n","    warmup_steps=120,                # number of warmup steps for learning rate scheduler\n","    weight_decay=0.01,               # strength of weight decay\n","    save_total_limit = 5,\n","    logging_dir='./logs',            # directory for storing logs\n","    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n","    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n","    # logging_steps=500,               # log & save weights each logging_steps\n","    save_strategy = \"epoch\",\n","    evaluation_strategy=\"epoch\",     # evaluate each `logging_steps`\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hwL5BOmdcC2q"},"outputs":[],"source":["trainer = Trainer(\n","    model=model,                         # the instantiated Transformers model to be trained\n","    args=training_args,                  # training arguments, defined above\n","    train_dataset=train_dataset,         # training dataset\n","    eval_dataset=valid_dataset,          # evaluation dataset\n","    compute_metrics=compute_metrics     # the callback that computes metrics of interest\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0WQ4PZ4ccC2q"},"outputs":[],"source":["# train the model\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rJVl3HTgcC2r"},"outputs":[],"source":["# evaluate the current model after training\n","trainer.evaluate()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iFc3Ak-kcC2r"},"outputs":[],"source":["predictions = trainer.predict(valid_dataset)\n","print(predictions.predictions.shape, predictions.label_ids.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OLNQQUIHcC2s"},"outputs":[],"source":["trues = [i[0] for i in predictions.label_ids]\n","preds = np.argmax(predictions.predictions, axis=-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xniUquYIcC2s"},"outputs":[],"source":["from sklearn.metrics import ConfusionMatrixDisplay\n","f,ax = plt.subplots(1,1,figsize=(40,40))\n","ConfusionMatrixDisplay.from_predictions(trues, preds, ax=ax)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GtO2Q_16cC2t"},"outputs":[],"source":["# saving the fine tuned model & tokenizer\n","model_path = \"pubmed_\" + PRE_TRAINED_MODEL_NAME\n","model.save_pretrained(model_path)\n","tokenizer.save_pretrained(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3yFr__jCcC2u"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_NoQjQLBcC2u"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.10 ('venv': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"0081987c862ade64fa8a6b449df670cc6c329610deb4a00a30d291630fdc88f2"}},"colab":{"provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}